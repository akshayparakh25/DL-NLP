{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../data/imdbtop1000/imdb_data.csv', sep='\\t')\n",
    "df = df.rename(columns={'User Votes': 'Votes',\n",
    "                        'Imdb Rating': 'Rating',\n",
    "                       'Gross(in Million Dollars)': 'Earnings',\n",
    "                       'Runtime(Minutes)' : 'Runtime'})\n",
    "\n",
    "dataframe = df[['Votes', 'Rating']]\n",
    "#It is very important to normalise the input features in a proper range\n",
    "#It helps in avoiding very large calculations\n",
    "dataframe['Votes'] = dataframe['Votes'] / 1000000\n",
    "dataframe['Rating'] = (dataframe.Rating > 7.6).astype(float)\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(dataframe, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, optimizers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "votes = tf.feature_column.numeric_column(\"Votes\")\n",
    "feature_columns.append(votes)\n",
    "\n",
    "feature_layer = layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(lr, feature_layer, metric):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(feature_layer)\n",
    "    model.add(layers.Dense(units=1, input_shape=(1,), activation=tf.sigmoid))\n",
    "    \n",
    "    model.compile(optimizer = optimizers.SGD(lr=lr),\n",
    "                 loss = losses.BinaryCrossentropy(),\n",
    "                 metrics = metric)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, label_name, epochs, batch_size=None, shuffle=True):\n",
    "    \n",
    "    features = {name:np.array(value) for name, value in dataset.items()}\n",
    "    label = np.array(features.pop(label_name))\n",
    "    \n",
    "    history = model.fit(x=features, y=label, epochs=epochs, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 300\n",
    "batch_size = 100\n",
    "label_name = \"Rating\"\n",
    "classification_threshold = 0.5\n",
    "\n",
    "METRIC = [tf.keras.metrics.BinaryAccuracy(name='accuracy',\n",
    "                                         threshold=classification_threshold)]\n",
    "\n",
    "model = build_model(learning_rate, feature_layer, METRIC)\n",
    "\n",
    "history = train_model(model=model, dataset=dataframe, label_name=label_name,\n",
    "                                    epochs=epochs, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(history.history)\n",
    "LOSS = history.loss\n",
    "ACCURACY = history.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11 ,5))\n",
    "\n",
    "ax0 = plt.subplot(121)\n",
    "ax0 = plt.plot(LOSS, label='LOSS')\n",
    "ax0 = plt.xlabel('epochs')\n",
    "ax0 = plt.ylabel('loss')\n",
    "\n",
    "ax1 = plt.subplot(122)\n",
    "ax1 = plt.plot(ACCURACY, label='ACCURACY')\n",
    "ax1 = plt.xlabel('epochs')\n",
    "ax1 = plt.ylabel('accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evalation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {name:np.array(value) for name, value in test.items()}\n",
    "label = np.array(features.pop(label_name))\n",
    "\n",
    "model.evaluate(x = features, y = label, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {name:np.array(value) for name, value in test.items()}\n",
    "label = np.array(features.pop(label_name))\n",
    "\n",
    "pred = model.predict(x = features, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (pred > 0.5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.scatterplot(x=features['Votes'],y=label, label='original', alpha=0.5)\n",
    "sns.scatterplot(x=features['Votes'],y=pred.reshape(-1,), label='predicted', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with more evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 300\n",
    "batch_size = 100\n",
    "label_name = \"Rating\"\n",
    "classification_threshold = 0.5\n",
    "\n",
    "METRIC = [tf.keras.metrics.BinaryAccuracy(name='accuracy',\n",
    "                                         threshold=classification_threshold),\n",
    "         tf.keras.metrics.Precision(name='precision',\n",
    "                                   thresholds=classification_threshold),\n",
    "         tf.keras.metrics.Recall(name='recall', \n",
    "                                 thresholds=classification_threshold)]\n",
    "\n",
    "model = build_model(learning_rate, feature_layer, METRIC)\n",
    "\n",
    "history = train_model(model=model, dataset=dataframe, label_name=label_name,\n",
    "                                    epochs=epochs, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(history.history)\n",
    "LOSS = history.loss\n",
    "ACCURACY = history.accuracy\n",
    "PRECISION = history.precision\n",
    "RECALL = history.recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11 ,5))\n",
    "\n",
    "ax0 = plt.subplot(121)\n",
    "ax0 = plt.plot(LOSS, label='LOSS')\n",
    "ax0 = plt.xlabel('epochs')\n",
    "ax0 = plt.ylabel('loss')\n",
    "\n",
    "ax1 = plt.subplot(122)\n",
    "ax1 = plt.plot(ACCURACY, label='ACCURACY')\n",
    "ax1 = plt.plot(PRECISION, label='PRECISION')\n",
    "ax1 = plt.plot(RECALL, label='RECALL')\n",
    "ax1 = plt.xlabel('epochs')\n",
    "ax1 = plt.ylabel('accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 300\n",
    "batch_size = 100\n",
    "label_name = \"Rating\"\n",
    "\n",
    "METRIC = [tf.keras.metrics.AUC(num_thresholds=100,\n",
    "                              name='auc')]\n",
    "\n",
    "model = build_model(learning_rate, feature_layer, METRIC)\n",
    "\n",
    "history = train_model(model=model, dataset=dataframe, label_name=label_name,\n",
    "                                    epochs=epochs, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(history.history)\n",
    "LOSS = history.loss\n",
    "AUC = history.auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11 ,5))\n",
    "\n",
    "ax0 = plt.subplot(121)\n",
    "ax0 = plt.plot(LOSS, label='LOSS')\n",
    "ax0 = plt.xlabel('epochs')\n",
    "ax0 = plt.ylabel('loss')\n",
    "\n",
    "ax1 = plt.subplot(122)\n",
    "ax1 = plt.plot(AUC, label='AUC')\n",
    "ax1 = plt.xlabel('epochs')\n",
    "ax1 = plt.ylabel('accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

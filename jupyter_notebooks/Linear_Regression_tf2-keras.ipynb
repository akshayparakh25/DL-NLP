{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset using Pandas\n",
    "For detailed explaination click [here](https://github.com/akshayparakh25/Python-for-Data_Science/blob/master/jupyter-notebooks/pandas.ipynb) <br>\n",
    "The dataset is available [here](https://github.com/akshayparakh25/imdb_1000_scraper/blob/master/imdb_data.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../data/imdbtop1000/imdb_data.csv', sep='\\t')\n",
    "df = df.rename(columns={'User Votes': 'Votes',\n",
    "                        'Imdb Rating': 'Rating',\n",
    "                       'Gross(in Million Dollars)': 'Earnings',\n",
    "                       'Runtime(Minutes)' : 'Runtime'})\n",
    "#It is very important to normalise the input features in a proper range\n",
    "#It helps in avoiding very large calculations\n",
    "df.Votes = df.Votes / 1000000\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical analysis of data to find the best input feature for target *quality*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation between columns to identify best feature for training a model\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Analysis of data points Votes Vs Rating\")\n",
    "sns.scatterplot(x=df.Votes, y=df.Rating)\n",
    "plt.xlabel('User Votes')\n",
    "plt.ylabel('IMDB Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with one variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining and building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(lr):\n",
    "    #initialise model :: Sequential Model\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    #Add layers to the model\n",
    "    model.add(tf.keras.layers.Dense(units=1,\n",
    "                                   input_shape=(1,)))\n",
    "    \n",
    "    #Compile model\n",
    "    #Configure training to minimize the model's mean squared error.\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=lr),\n",
    "#                     optimizer=tf.keras.optimizers.RMSprop(lr=lr),\n",
    "                 loss=\"mean_squared_error\",\n",
    "#                  metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "                 )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = build_model(0.1)\n",
    "dummy_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, features, label, epochs, batch_size):\n",
    "    #Feeding the model training data\n",
    "    history = model.fit(x=dataset[features],\n",
    "                        y=dataset[label],\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs)\n",
    "    \n",
    "    weight = model.get_weights()[0]\n",
    "    bias = model.get_weights()[1]\n",
    "    \n",
    "    return weight, bias, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 15\n",
    "batch_size = len(df)\n",
    "\n",
    "feature = \"Votes\"\n",
    "label = \"Rating\"\n",
    "\n",
    "model = build_model(learning_rate)\n",
    "\n",
    "w, b, hist = train(model, dataset=df, features=feature, label=label, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w[0][0])\n",
    "print(b[0])\n",
    "predictions = w[0][0] * df.Votes + b[0]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Analysis of trained model and data points\")\n",
    "sns.scatterplot(x=df.Votes, y=df.Rating)\n",
    "sns.lineplot(x=df.Votes, y=predictions, color='red')\n",
    "plt.xlabel('User Votes')\n",
    "plt.ylabel('IMDB Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = pd.DataFrame(hist.history)['loss']\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(LOSS, label='BGD')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 15\n",
    "batch_size = 1\n",
    "\n",
    "feature = \"Votes\"\n",
    "label = \"Rating\"\n",
    "\n",
    "model = build_model(learning_rate)\n",
    "\n",
    "w, b, hist = train(model, dataset=df, features=feature, label=label, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w[0][0])\n",
    "print(b[0])\n",
    "predictions = w[0][0] * df.Votes + b[0]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Analysis of trained model and data points\")\n",
    "sns.scatterplot(x=df.Votes, y=df.Rating)\n",
    "sns.lineplot(x=df.Votes, y=predictions, color='red')\n",
    "plt.xlabel('User Votes')\n",
    "plt.ylabel('IMDB Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = pd.DataFrame(hist.history)['loss']\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(LOSS, label='BGD')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 15\n",
    "batch_size = 10\n",
    "\n",
    "feature = \"Votes\"\n",
    "label = \"Rating\"\n",
    "\n",
    "model = build_model(learning_rate)\n",
    "\n",
    "w, b, hist = train(model, dataset=df, features=feature, label=label, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w[0][0])\n",
    "print(b[0])\n",
    "predictions = w[0][0] * df.Votes + b[0]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Analysis of trained model and data points\")\n",
    "sns.scatterplot(x=df.Votes, y=df.Rating)\n",
    "sns.lineplot(x=df.Votes, y=predictions, color='red')\n",
    "plt.xlabel('User Votes')\n",
    "plt.ylabel('IMDB Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = pd.DataFrame(hist.history)['loss']\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(LOSS, label='MBGD')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../data/imdbtop1000/imdb_data.csv', sep='\\t')\n",
    "df = df.rename(columns={'User Votes': 'Votes',\n",
    "                        'Imdb Rating': 'Rating',\n",
    "                       'Gross(in Million Dollars)': 'Earnings',\n",
    "                       'Runtime(Minutes)' : 'Runtime'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = df[['Votes', 'Earnings', 'Rating']]\n",
    "#It is very important to normalise the input features in a proper range\n",
    "#It helps in avoiding very large calculations\n",
    "dataframe['Votes'] = dataframe['Votes'] / 1000000\n",
    "dataframe['Earnings'] = dataframe['Earnings'] / 100\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 73 (1000 - 927) rows with NaN/nan values\n",
    "#Drop those rows\n",
    "dataframe.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty dataframe confirms abscence of rows with nan/NaN\n",
    "dataframe[dataframe.Earnings.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Feature Column\n",
    "feature_columns = []\n",
    "\n",
    "#Creating a numerical feature columns to represent Rating and Earning features\n",
    "votes = tf.feature_column.numeric_column(\"Votes\")\n",
    "feature_columns.append(votes)\n",
    "\n",
    "earnings = tf.feature_column.numeric_column(\"Earnings\")\n",
    "feature_columns.append(earnings)\n",
    "\n",
    "#Converting the list of features into a layer that will be fed to the network\n",
    "feature_layer = layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(lr, feature_layer):\n",
    "    #initialise model :: Sequential Model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #adding feature layer\n",
    "    model.add(feature_layer)\n",
    "    \n",
    "    #Add layers to the model\n",
    "    model.add(layers.Dense(units=1, input_shape=(2,)))\n",
    "    \n",
    "    #Compile model\n",
    "    #Configure training to minimize the model's mean squared error.\n",
    "    model.compile(optimizer=optimizers.SGD(lr=lr),\n",
    "                    loss=\"mean_squared_error\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, label_name, epochs, batch_size):\n",
    "    #Here, we're passing\n",
    "    # every column in the dataset. Note that the feature_layer will filter\n",
    "    # away most of those columns, leaving only the desired columns and their\n",
    "    # representations as features.\n",
    "    features = {name:np.array(value) for name, value in dataset.items()}\n",
    "    label = np.array(features.pop(label_name)) \n",
    "    \n",
    "    \n",
    "    #Feeding the model training data\n",
    "    history = model.fit(features,\n",
    "                        label,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 50\n",
    "batch_size = len(df)\n",
    "\n",
    "label = \"Rating\"\n",
    "\n",
    "model = build_model(learning_rate, feature_layer)\n",
    "\n",
    "trained_model, hist = train(model, dataset=dataframe, label_name=label, epochs=epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = pd.DataFrame(hist.history)['loss']\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(LOSS, label='LOSS')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
